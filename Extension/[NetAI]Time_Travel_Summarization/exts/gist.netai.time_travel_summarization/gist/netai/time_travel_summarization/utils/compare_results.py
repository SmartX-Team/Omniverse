"""
VLM Object Detection ê²°ê³¼ ë¹„êµ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” VLM ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì •ë‹µ(Ground Truth)ê³¼ ë¹„êµí•˜ì—¬
Precision, Recall, F1 Scoreë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    # ê¸°ë³¸ ì‚¬ìš© (Ground Truth 2 ì‚¬ìš©, outputs í´ë”ì˜ ëª¨ë“  JSON íŒŒì¼ ì²˜ë¦¬)
    python compare_results.py
    
    # íŠ¹ì • Ground Truth ì„ íƒ (1, 2, 3, 4 ì¤‘ ì„ íƒ)
    python compare_results.py -g 1
    python compare_results.py --ground-truth 3
    
    # íŠ¹ì • JSON íŒŒì¼ë§Œ ì²˜ë¦¬
    python compare_results.py -f video_19.json
    python compare_results.py --file Qwen3-VL-8B-Instruct_video_19_20251201_123456.json
    
    # Ground Truthì™€ íŒŒì¼ ëª¨ë‘ ì§€ì •
    python compare_results.py -g 2 -f video_19.json
    
    # ë„ì›€ë§ ë³´ê¸°
    python compare_results.py -h

ì¶œë ¥:
    - ì½˜ì†”: ìƒì„¸í•œ ë¹„êµ ê²°ê³¼ (ì™„ì „ ì¼ì¹˜, ë¶€ë¶„ ì¼ì¹˜, ëˆ„ë½, ì¶”ê°€ ì˜ˆì¸¡)
    - íŒŒì¼: compare_outputs/{ì›ë³¸íŒŒì¼ëª…}__comparison_result.json
            (Precision, Recall, F1 Score ë° ìƒì„¸ ê²°ê³¼ í¬í•¨)

Ground Truth:
    1: video_18.mp4 (12ê°œ ì´ë²¤íŠ¸)
    2: video_19.mp4 (7ê°œ ì´ë²¤íŠ¸)  <- ê¸°ë³¸ê°’
    3: video_30.mp4 (9ê°œ ì´ë²¤íŠ¸)
    4: video_31.mp4 (4ê°œ ì´ë²¤íŠ¸)
"""

import json
import re
import argparse
from typing import Dict, Set, List, Tuple
from pathlib import Path


def parse_ground_truth(gt_text: str) -> Dict[str, Set[int]]:
    """
    ì •ë‹µì§€ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    
    Args:
        gt_text: ì •ë‹µì§€ í…ìŠ¤íŠ¸ (ì˜ˆ: "00:00:28 1,4")
    
    Returns:
        {timestamp: set of object ids}
    """
    ground_truth = {}
    for line in gt_text.strip().split('\n'):
        if not line.strip():
            continue
        parts = line.strip().split()
        if len(parts) >= 2:
            timestamp = parts[0]
            obj_ids = set(int(x.strip()) for x in parts[1].split(','))
            ground_truth[timestamp] = obj_ids
    return ground_truth


def parse_prediction_json(json_path: str) -> Dict[str, List[Set[int]]]:
    """
    ì˜ˆì¸¡ ê²°ê³¼ JSON íŒŒì¼ì„ íŒŒì‹±
    - contentê°€ ì½”ë“œë¸”ë¡(````json ... ````)ì¸ì§€
    - ì¼ë°˜ JSON ë°°ì—´ ë¬¸ìì—´ì¸ì§€ ë‘˜ ë‹¤ ì²˜ë¦¬
    - ê°™ì€ timestampì— ëŒ€í•œ ì—¬ëŸ¬ ì˜ˆì¸¡ì„ Listë¡œ ë³´ì¡´
    """
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    predictions = {}

    for chunk in data.get('chunk_responses', []):
        content = chunk.get('content', '').strip()

        # 1) ì½”ë“œë¸”ë¡ JSON ì²˜ë¦¬
        json_match = re.search(r'```json\s*(\[.*?\])\s*```', content, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # 2) ì¼ë°˜ JSON ë¬¸ìì—´ì¼ ê²½ìš°
            # content ìì²´ê°€ JSON ë°°ì—´ì¸ì§€ í™•ì¸
            if content.startswith('[') and content.endswith(']'):
                json_str = content
            else:
                # JSONì´ ì•„ì˜ˆ ì—†ìœ¼ë©´ ê·¸ëƒ¥ skip
                continue

        # JSON ë¡œë“œ ì‹œë„
        try:
            items = json.loads(json_str)
            for item in items:
                if isinstance(item, dict):
                    for timestamp, obj_ids in item.items():
                        obj_set = set(obj_ids)
                        # ê°™ì€ timestampì— ëŒ€í•´ ì¤‘ë³µëœ ì˜ˆì¸¡ì€ ì œê±°í•˜ë˜,
                        # ë‹¤ë¥¸ ì˜ˆì¸¡ì€ ë³„ë„ë¡œ ë³´ì¡´
                        if timestamp not in predictions:
                            predictions[timestamp] = []
                        # ë™ì¼í•œ ì˜ˆì¸¡ì´ ì•„ë‹ˆë©´ ì¶”ê°€ (setì´ë¯€ë¡œ ìˆœì„œ ë¬´ê´€ ë¹„êµ)
                        if obj_set not in predictions[timestamp]:
                            predictions[timestamp].append(obj_set)
        except json.JSONDecodeError as e:
            print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            print(f"ë¬¸ì œ content:\n{content}")

    return predictions

def calculate_metrics(ground_truth: Dict[str, Set[int]], 
                     predictions: Dict[str, List[Set[int]]]) -> Tuple[float, float, float, Dict]:
    """
    Precision, Recall, F1 Score ê³„ì‚°
    ì™„ì „ ì¼ì¹˜ë§Œ True Positiveë¡œ íŒì •
    
    Args:
        ground_truth: ì •ë‹µ ë°ì´í„° {timestamp: set of object ids}
        predictions: ì˜ˆì¸¡ ë°ì´í„° {timestamp: list of sets of object ids}
    
    Returns:
        (precision, recall, f1, details)
    """
    true_positives = 0
    false_positives = 0
    false_negatives = 0
    
    details = {
        'correct': [],
        'missing_timestamps': [],
        'extra_timestamps': [],
        'incorrect_predictions': []
    }
    
    all_timestamps = set(ground_truth.keys()) | set(predictions.keys())
    
    for timestamp in sorted(all_timestamps):
        gt_objects = ground_truth.get(timestamp, set())
        pred_list = predictions.get(timestamp, [])
        
        if timestamp not in ground_truth:
            # ì˜ˆì¸¡í–ˆì§€ë§Œ ì •ë‹µì— ì—†ëŠ” íƒ€ì„ìŠ¤íƒ¬í”„ - ëª¨ë‘ FP
            for pred_objects in pred_list:
                details['extra_timestamps'].append({
                    'timestamp': timestamp,
                    'predicted': sorted(pred_objects)
                })
                false_positives += 1
                
        elif timestamp not in predictions or len(pred_list) == 0:
            # ì •ë‹µì— ìˆì§€ë§Œ ì˜ˆì¸¡í•˜ì§€ ëª»í•œ íƒ€ì„ìŠ¤íƒ¬í”„ - FN
            details['missing_timestamps'].append({
                'timestamp': timestamp,
                'ground_truth': sorted(gt_objects)
            })
            false_negatives += 1
            
        else:
            # ë‘˜ ë‹¤ ìˆëŠ” ê²½ìš° - ê° ì˜ˆì¸¡ì„ ê°œë³„ íŒì •
            for pred_objects in pred_list:
                if pred_objects == gt_objects:
                    # ì™„ì „ ì¼ì¹˜ - TP
                    true_positives += 1
                    details['correct'].append({
                        'timestamp': timestamp,
                        'objects': sorted(gt_objects)
                    })
                else:
                    # ë¶ˆì¼ì¹˜ - FP (í‹€ë¦° ì˜ˆì¸¡)
                    false_positives += 1
                    details['incorrect_predictions'].append({
                        'timestamp': timestamp,
                        'ground_truth': sorted(gt_objects),
                        'predicted': sorted(pred_objects)
                    })
            
            # FNì€ ì œê±°: ì˜ˆì¸¡ì„ í–ˆìœ¼ë©´ FNì´ ì•„ë‹˜
    
    # Precision, Recall, F1 ê³„ì‚°
    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    
    return precision, recall, f1, details


def print_comparison_report(precision: float, recall: float, f1: float, details: Dict):
    """ë¹„êµ ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥"""
    print("=" * 80)
    print("Object Detection ë¹„êµ ê²°ê³¼ (ì™„ì „ ì¼ì¹˜ë§Œ ì •ë‹µ)")
    print("=" * 80)
    print(f"\nğŸ“Š ì„±ëŠ¥ ì§€í‘œ:")
    print(f"  Precision: {precision:.2f} ({precision*100:.2f}%)")
    print(f"  Recall:    {recall:.2f} ({recall*100:.2f}%)")
    print(f"  F1 Score:  {f1:.2f} ({f1*100:.2f}%)")
    
    print(f"\nâœ… ì™„ì „íˆ ì¼ì¹˜í•˜ëŠ” ì˜ˆì¸¡: {len(details['correct'])}ê°œ")
    for item in details['correct']:
        print(f"  {item['timestamp']}: {item['objects']}")
    
    if details['incorrect_predictions']:
        print(f"\nâŒ í‹€ë¦° ì˜ˆì¸¡: {len(details['incorrect_predictions'])}ê°œ")
        for item in details['incorrect_predictions']:
            print(f"  {item['timestamp']}:")
            print(f"    ì •ë‹µ: {item['ground_truth']}")
            print(f"    ì˜ˆì¸¡: {item['predicted']}")
    
    if details['missing_timestamps']:
        print(f"\nâš ï¸  ì˜ˆì¸¡í•˜ì§€ ëª»í•œ íƒ€ì„ìŠ¤íƒ¬í”„: {len(details['missing_timestamps'])}ê°œ")
        for item in details['missing_timestamps']:
            print(f"  {item['timestamp']}: {item['ground_truth']}")
    
    if details['extra_timestamps']:
        print(f"\nâ• ì •ë‹µì— ì—†ëŠ” íƒ€ì„ìŠ¤íƒ¬í”„ ì˜ˆì¸¡: {len(details['extra_timestamps'])}ê°œ")
        for item in details['extra_timestamps']:
            print(f"  {item['timestamp']}: {item['predicted']}")
    
    print("\n" + "=" * 80)


def get_ground_truth_texts():
    """ëª¨ë“  ground truth ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜"""
    return {
        '1': """
00:00:00 2,4
00:00:28 1,4
00:00:30 2,4
00:00:31 2,4
00:00:33 3,4
00:00:39 1,4
00:00:40 1,4
00:00:41 1,3
00:00:42 1,3
00:00:51 2,4
00:00:54 2,3
00:00:56 1,2
00:00:57 1,2
        """,
        '2': """
00:00:01 1,2
00:00:02 1,2
00:00:31 2,3
00:00:41 1,3
00:00:48 1,2
00:00:54 3,4
00:00:55 3,4
        """,
        '3': """
00:00:06 1,4
00:00:15 1,3
00:00:19 3,4
00:00:21 2,4
00:00:23 2,3
00:00:24 2,3
00:00:43 1,3
00:00:45 2,4
00:00:57 3,4
        """,
        '4': """
00:00:18 2,3
00:00:30 2,3
00:00:42 1,2
00:00:46 2,4
        """
    }


def main():
    # ì»¤ë§¨ë“œë¼ì¸ ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(
        description="VLM ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì •ë‹µê³¼ ë¹„êµí•˜ì—¬ Precision, Recall, F1 Scoreë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."
    )
    parser.add_argument(
        '-g', '--ground-truth',
        type=str,
        default='2',
        choices=['1', '2', '3', '4'],
        help='ì‚¬ìš©í•  ground truth ë²ˆí˜¸ (ê¸°ë³¸ê°’: 2)'
    )
    parser.add_argument(
        '-f', '--file',
        type=str,
        default=None,
        help='íŠ¹ì • JSON íŒŒì¼ë§Œ ì²˜ë¦¬ (íŒŒì¼ëª…ë§Œ ì…ë ¥, ì˜ˆ: video_19.json)'
    )
    
    args = parser.parse_args()
    
    # Ground truth ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    ground_truth_texts = get_ground_truth_texts()
    selected_gt_text = ground_truth_texts[args.ground_truth]
    
    print(f"ğŸ¯ Ground Truth {args.ground_truth} ì‚¬ìš©")
    print("=" * 80)
    
    # outputs í´ë” (utilsì™€ ê°™ì€ ìƒìœ„ ë””ë ‰í† ë¦¬)
    outputs_dir = Path(__file__).parent.parent / "outputs"

    # compare_outputs í´ë” ìƒì„±
    compare_outputs_dir = Path(__file__).parent.parent / "compare_outputs"
    compare_outputs_dir.mkdir(exist_ok=True)

    # JSON íŒŒì¼ í•„í„°ë§
    if args.file:
        # íŠ¹ì • íŒŒì¼ë§Œ ì²˜ë¦¬
        json_files = [outputs_dir / args.file]
        if not json_files[0].exists():
            print(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_files[0]}")
            return
    else:
        # ëª¨ë“  json íŒŒì¼ ìˆœíšŒ
        json_files = sorted(outputs_dir.glob("*.json"))

    if not json_files:
        print("âš ï¸ outputs í´ë”ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    for json_file in json_files:
        print(f"\nğŸ“„ ì²˜ë¦¬ ì¤‘: {json_file.name}")

        # íŒŒì‹±
        ground_truth = parse_ground_truth(selected_gt_text)
        predictions = parse_prediction_json(str(json_file))

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        precision, recall, f1, details = calculate_metrics(ground_truth, predictions)

        # ê²°ê³¼ ì¶œë ¥
        print_comparison_report(precision, recall, f1, details)

        # ê²°ê³¼ íŒŒì¼ëª…: {jsoníŒŒì¼ëª…}__comparison_result.json
        result_filename = f"{json_file.stem}__comparison_result.json"
        result_file = compare_outputs_dir / result_filename

        # JSON ì €ì¥ (ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ë¡œ ë°˜ì˜¬ë¦¼)
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump({
                'source_file': json_file.name,
                'metrics': {
                    'precision': round(precision, 2),
                    'recall': round(recall, 2),
                    'f1_score': round(f1, 2)
                },
                'details': details
            }, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {result_file}")

    print("\nğŸ‰ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
