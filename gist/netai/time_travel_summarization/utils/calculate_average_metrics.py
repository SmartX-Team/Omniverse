#!/usr/bin/env python3
"""
ì—¬ëŸ¬ JSON ë¹„êµ ê²°ê³¼ íŒŒì¼ì—ì„œ metricsì˜ í‰ê· ì„ ê³„ì‚°í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python calculate_average_metrics.py <íŒŒì¼íŒ¨í„´>
    
ì˜ˆì‹œ:
    python calculate_average_metrics.py "../compare_outputs/video_18_*.json"
    python calculate_average_metrics.py "../compare_outputs/gpt_video_21_*.json"
"""

import json
import glob
import sys
import os
from typing import List, Dict


def load_metrics_from_files(file_pattern: str) -> List[Dict[str, float]]:
    """
    íŒŒì¼ íŒ¨í„´ì— ë§ëŠ” JSON íŒŒì¼ë“¤ì„ ì½ì–´ì„œ metrics ëª©ë¡ì„ ë°˜í™˜
    
    Args:
        file_pattern: glob íŒ¨í„´ (ì˜ˆ: "video_18_*.json")
        
    Returns:
        ê° íŒŒì¼ì˜ metrics ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    files = sorted(glob.glob(file_pattern))
    
    if not files:
        print(f"âŒ íŒ¨í„´ '{file_pattern}'ì— ë§ëŠ” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    print(f"ğŸ“‚ {len(files)}ê°œì˜ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:")
    for f in files:
        print(f"   - {os.path.basename(f)}")
    print()
    
    metrics_list = []
    
    for file_path in files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            if 'metrics' not in data:
                print(f"âš ï¸  ê²½ê³ : {os.path.basename(file_path)}ì— 'metrics' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
                
            metrics = data['metrics']
            
            # í•„ìš”í•œ í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸
            required_keys = ['precision', 'recall', 'f1_score']
            if all(key in metrics for key in required_keys):
                metrics_list.append(metrics)
            else:
                missing = [key for key in required_keys if key not in metrics]
                print(f"âš ï¸  ê²½ê³ : {os.path.basename(file_path)}ì— {missing} í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                
        except json.JSONDecodeError as e:
            print(f"âŒ {os.path.basename(file_path)} JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        except Exception as e:
            print(f"âŒ {os.path.basename(file_path)} ì½ê¸° ì˜¤ë¥˜: {e}")
    
    return metrics_list


def calculate_average_metrics(metrics_list: List[Dict[str, float]]) -> Dict[str, float]:
    """
    metrics ë¦¬ìŠ¤íŠ¸ì—ì„œ í‰ê· ì„ ê³„ì‚°
    
    Args:
        metrics_list: metrics ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        í‰ê·  metrics ë”•ì…”ë„ˆë¦¬
    """
    if not metrics_list:
        return {}
    
    n = len(metrics_list)
    
    avg_precision = sum(m['precision'] for m in metrics_list) / n
    avg_recall = sum(m['recall'] for m in metrics_list) / n
    avg_f1 = sum(m['f1_score'] for m in metrics_list) / n
    
    return {
        'precision': avg_precision,
        'recall': avg_recall,
        'f1_score': avg_f1,
        'num_files': n
    }


def print_results(avg_metrics: Dict[str, float], metrics_list: List[Dict[str, float]]):
    """ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
    if not avg_metrics:
        print("âŒ ê³„ì‚°í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("=" * 60)
    print("ğŸ“Š í‰ê·  Metrics ê²°ê³¼")
    print("=" * 60)
    print(f"ë¶„ì„ëœ íŒŒì¼ ìˆ˜: {avg_metrics['num_files']}ê°œ\n")
    
    print(f"Average Precision: {avg_metrics['precision']:.4f}")
    print(f"Average Recall:    {avg_metrics['recall']:.4f}")
    print(f"Average F1 Score:  {avg_metrics['f1_score']:.4f}")
    print("=" * 60)
    
    # ê°œë³„ íŒŒì¼ ê²°ê³¼ë„ í‘œì‹œ
    print("\nğŸ“‹ ê°œë³„ íŒŒì¼ Metrics:")
    print("-" * 60)
    print(f"{'#':<4} {'Precision':<12} {'Recall':<12} {'F1 Score':<12}")
    print("-" * 60)
    
    for i, m in enumerate(metrics_list, 1):
        print(f"{i:<4} {m['precision']:<12.4f} {m['recall']:<12.4f} {m['f1_score']:<12.4f}")
    print("-" * 60)


def save_results(avg_metrics: Dict[str, float], metrics_list: List[Dict[str, float]], 
                 output_file: str):
    """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    result = {
        'average_metrics': {
            'precision': avg_metrics['precision'],
            'recall': avg_metrics['recall'],
            'f1_score': avg_metrics['f1_score']
        },
        'num_files': avg_metrics['num_files'],
        'individual_metrics': metrics_list
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ ê²°ê³¼ê°€ '{output_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def main():
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python calculate_average_metrics.py <íŒŒì¼íŒ¨í„´>")
        print("\nì˜ˆì‹œ:")
        print('  python calculate_average_metrics.py "../compare_outputs/video_18_*.json"')
        print('  python calculate_average_metrics.py "../compare_outputs/gpt_video_21_*.json"')
        sys.exit(1)
    
    file_pattern = sys.argv[1]
    
    # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œ ì²˜ë¦¬
    if not os.path.isabs(file_pattern):
        file_pattern = os.path.abspath(file_pattern)
    
    print(f"ğŸ” íŒŒì¼ íŒ¨í„´: {file_pattern}\n")
    
    # metrics ë¡œë“œ
    metrics_list = load_metrics_from_files(file_pattern)
    
    if not metrics_list:
        sys.exit(1)
    
    # í‰ê·  ê³„ì‚°
    avg_metrics = calculate_average_metrics(metrics_list)
    
    # ê²°ê³¼ ì¶œë ¥
    print_results(avg_metrics, metrics_list)
    
    # ê²°ê³¼ ìë™ ì €ì¥
    # íŒ¨í„´ì—ì„œ ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
    pattern_base = os.path.basename(file_pattern)
    # ì™€ì¼ë“œì¹´ë“œ íŒ¨í„´ì„ í‰ê·  ê²°ê³¼ íŒŒì¼ëª…ìœ¼ë¡œ ë³€í™˜
    pattern_base = pattern_base.replace('*', '').replace('__', '_').replace('comparison_result.json', 'average_metrics.json')
    if not pattern_base.endswith('.json'):
        pattern_base = pattern_base.replace('.json', '') + 'average_metrics.json'
    
    output_dir = os.path.dirname(file_pattern)
    output_file = os.path.join(output_dir, pattern_base)
    
    save_results(avg_metrics, metrics_list, output_file)


if __name__ == '__main__':
    main()
